{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5575e288",
   "metadata": {},
   "source": [
    "# Matrix Factorization for Recipe Recommendation\n",
    "This notebook demonstrates how to use matrix factorization (SVD) for building a recipe recommendation system using the Cornac library. It covers data loading, model training, evaluation, and analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a4de48",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "We import all necessary libraries, including Cornac for recommendation, pandas and numpy for data handling, and a custom DataLoader for loading the recipe data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94a49d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install import_ipynb\n",
    "import import_ipynb \n",
    "import cornac\n",
    "from cornac.data import Dataset\n",
    "from cornac.eval_methods import BaseMethod\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cornac\n",
    "from cornac.models import SVD\n",
    "from cornac.data import Dataset\n",
    "from cornac.eval_methods import RatioSplit\n",
    "import cornac.metrics as metrics\n",
    "import cornac.metrics as met\n",
    "from data_loader import DataLoader # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa556890",
   "metadata": {},
   "source": [
    "## 2. Load Data\n",
    "We use a custom DataLoader to load the training and test datasets for the recommendation task. The data consists of user (AuthorId), item (RecipeId), and rating (Rating) columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1925b042",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/\"\n",
    "data_loader = DataLoader(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cb3f3ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(513384, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ReviewId</th>\n",
       "      <th>RecipeId</th>\n",
       "      <th>AuthorId</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>826743</td>\n",
       "      <td>3745</td>\n",
       "      <td>345380</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1247176</td>\n",
       "      <td>26217</td>\n",
       "      <td>406131</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1250914</td>\n",
       "      <td>17123</td>\n",
       "      <td>355582</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>183560</td>\n",
       "      <td>123283</td>\n",
       "      <td>58104</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1255493</td>\n",
       "      <td>110139</td>\n",
       "      <td>383795</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ReviewId  RecipeId  AuthorId  Rating\n",
       "0    826743      3745    345380       4\n",
       "1   1247176     26217    406131       1\n",
       "2   1250914     17123    355582       5\n",
       "3    183560    123283     58104       4\n",
       "4   1255493    110139    383795       5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset, test_dataset = data_loader.load_for_cornac(dataset_type='split')\n",
    "print(train_dataset.shape)\n",
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6542a8",
   "metadata": {},
   "source": [
    "## 3. Initialize and Configure the SVD Model\n",
    "We initialize the SVD (Singular Value Decomposition) model from Cornac with specified hyperparameters such as the number of latent factors, learning rate, and regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "651ff8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SVD Matrix Factorization Implementation ===\n",
      "SVD Model Configuration:\n",
      "- Latent factors (k): 50\n",
      "- Max iterations: 100\n",
      "- Learning rate: 0.01\n",
      "- Regularization: 0.02\n"
     ]
    }
   ],
   "source": [
    "# 1. Initialize and configure the SVD model\n",
    "print(\"=== SVD Matrix Factorization Implementation ===\")\n",
    "\n",
    "# Basic SVD model with default parameters\n",
    "svd_model = SVD(\n",
    "    k=50,           # Number of latent factors\n",
    "    max_iter=100,   # Maximum number of iterations\n",
    "    learning_rate=0.01,  # Learning rate for SGD\n",
    "    lambda_reg=0.02,     # Regularization parameter\n",
    "    verbose=True,        # Print training progress\n",
    "    seed=123            # Random seed for reproducibility\n",
    ")\n",
    "\n",
    "print(f\"SVD Model Configuration:\")\n",
    "print(f\"- Latent factors (k): {svd_model.k}\")\n",
    "print(f\"- Max iterations: {svd_model.max_iter}\")\n",
    "print(f\"- Learning rate: {svd_model.learning_rate}\")\n",
    "print(f\"- Regularization: {svd_model.lambda_reg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca411126",
   "metadata": {},
   "source": [
    "## 4. Data Preparation\n",
    "We ensure the data is in the correct format for Cornac, converting the DataFrame to a list of (user, item, rating) tuples if necessary. This step also prints basic statistics about the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c053a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Data Preparation ===\n",
      "Original data structure:\n",
      "   ReviewId  RecipeId  AuthorId  Rating\n",
      "0    826743      3745    345380       4\n",
      "1   1247176     26217    406131       1\n",
      "2   1250914     17123    355582       5\n",
      "3    183560    123283     58104       4\n",
      "4   1255493    110139    383795       5\n",
      "Columns: ['ReviewId', 'RecipeId', 'AuthorId', 'Rating']\n",
      "Training data shape: 17748 users, 39057 items\n",
      "Number of ratings: 513384\n",
      "Rating scale: 0.0 to 5.0\n",
      "Test data: 16131 users, 34075 items\n"
     ]
    }
   ],
   "source": [
    "# 2. Prepare the data correctly\n",
    "print(\"\\n=== Data Preparation ===\")\n",
    "try:\n",
    "    # Fix the data structure - use correct columns: AuthorId as user, RecipeId as item, Rating as rating\n",
    "    if isinstance(train_dataset, pd.DataFrame):\n",
    "        print(\"Original data structure:\")\n",
    "        print(train_dataset.head())\n",
    "        print(f\"Columns: {train_dataset.columns.tolist()}\")\n",
    "        \n",
    "        # Create correct format: (user_id, item_id, rating)\n",
    "        # Use AuthorId as user_id, RecipeId as item_id, Rating as rating\n",
    "        train_tuples = [(row.AuthorId, row.RecipeId, row.Rating) \n",
    "                       for row in train_dataset.itertuples(index=False)]\n",
    "        \n",
    "        train_data = Dataset.from_uir(train_tuples, seed=123)\n",
    "        \n",
    "        print(f\"Training data shape: {len(train_data.user_ids)} users, {len(train_data.item_ids)} items\")\n",
    "        print(f\"Number of ratings: {train_data.num_ratings}\")\n",
    "        print(f\"Rating scale: {train_data.min_rating} to {train_data.max_rating}\")\n",
    "        \n",
    "        # Do the same for test data if available\n",
    "        if 'test_dataset' in locals() and isinstance(test_dataset, pd.DataFrame):\n",
    "            test_tuples = [(row.AuthorId, row.RecipeId, row.Rating) \n",
    "                          for row in test_dataset.itertuples(index=False)]\n",
    "            test_data = Dataset.from_uir(test_tuples, seed=123)\n",
    "            print(f\"Test data: {len(test_data.user_ids)} users, {len(test_data.item_ids)} items\")\n",
    "    else:\n",
    "        train_data = train_dataset\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Data preparation error: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e838fb8",
   "metadata": {},
   "source": [
    "## 5. Train the SVD Model\n",
    "We fit the SVD model to the training data and check the learned user and item factor matrices for NaN values and correct shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "104cae1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training SVD Model ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "005365840db54356aaead1e09faafa34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization finished!\n",
      "SVD model training completed successfully!\n",
      "User factors matrix shape: (17748, 50)\n",
      "Item factors matrix shape: (39057, 50)\n",
      "NaN values in user factors: 0\n",
      "NaN values in item factors: 0\n"
     ]
    }
   ],
   "source": [
    "# 3. Train the SVD model\n",
    "print(\"\\n=== Training SVD Model ===\")\n",
    "try:\n",
    "    svd_model.fit(train_data)\n",
    "    print(\"SVD model training completed successfully!\")\n",
    "    \n",
    "    # Access the learned matrices using correct attributes\n",
    "    print(f\"User factors matrix shape: {svd_model.u_factors.shape}\")\n",
    "    print(f\"Item factors matrix shape: {svd_model.i_factors.shape}\")\n",
    "    \n",
    "    # Check for NaN values in the factors\n",
    "    user_nan_count = np.isnan(svd_model.u_factors).sum()\n",
    "    item_nan_count = np.isnan(svd_model.i_factors).sum()\n",
    "    print(f\"NaN values in user factors: {user_nan_count}\")\n",
    "    print(f\"NaN values in item factors: {item_nan_count}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Training error: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ea8ca4",
   "metadata": {},
   "source": [
    "## 6. Generate Predictions and Recommendations\n",
    "We define utility functions to generate top-k recommendations for a user and to predict ratings for specific user-item pairs. We test these functions with sample users from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1332d6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Generating Recommendations ===\n",
      "\n",
      "Top-5 recommendations for user 345380:\n",
      "  1. Recipe 23089: Score 5.524\n",
      "  2. Recipe 17874: Score 5.411\n",
      "  3. Recipe 29124: Score 5.347\n",
      "  4. Recipe 1631: Score 5.310\n",
      "  5. Recipe 31005: Score 5.290\n",
      "  Predicted rating for recipe 3745: 4.846\n",
      "\n",
      "Top-5 recommendations for user 406131:\n",
      "  1. Recipe 23089: Score 5.524\n",
      "  2. Recipe 17874: Score 5.411\n",
      "  3. Recipe 29124: Score 5.347\n",
      "  4. Recipe 1631: Score 5.310\n",
      "  5. Recipe 31005: Score 5.290\n",
      "  Predicted rating for recipe 26217: 4.682\n",
      "\n",
      "Top-5 recommendations for user 355582:\n",
      "  1. Recipe 23089: Score 5.524\n",
      "  2. Recipe 17874: Score 5.411\n",
      "  3. Recipe 29124: Score 5.347\n",
      "  4. Recipe 1631: Score 5.310\n",
      "  5. Recipe 31005: Score 5.290\n",
      "  Predicted rating for recipe 17123: 4.760\n"
     ]
    }
   ],
   "source": [
    "# 4. Generate predictions and recommendations (Fixed)\n",
    "print(\"\\n=== Generating Recommendations ===\")\n",
    "\n",
    "def get_user_recommendations_fixed(model, user_id, train_data, k=5):\n",
    "    \"\"\"Generate top-k recommendations for a user - Fixed version\"\"\"\n",
    "    try:\n",
    "        # Check if user exists in training data\n",
    "        if user_id not in train_data.user_ids:\n",
    "            print(f\"User {user_id} not found in training data\")\n",
    "            return None\n",
    "            \n",
    "        # Get user index\n",
    "        user_idx = train_data.uid_map[user_id]\n",
    "        \n",
    "        # Get all items the user hasn't rated\n",
    "        user_items = set(train_data.matrix[user_idx].indices)\n",
    "        all_items = set(range(len(train_data.item_ids)))\n",
    "        candidate_items = all_items - user_items\n",
    "        \n",
    "        # Score candidate items\n",
    "        item_scores = []\n",
    "        for item_idx in candidate_items:\n",
    "            try:\n",
    "                item_id = train_data.item_ids[item_idx]\n",
    "                score = model.score(user_id, item_id)\n",
    "                if not np.isnan(score):\n",
    "                    item_scores.append((item_id, score))\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        # Sort by score and return top-k\n",
    "        item_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "        return item_scores[:k]\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Recommendation error for user {user_id}: {e}\")\n",
    "        return None\n",
    "\n",
    "def predict_rating_fixed(model, user_id, item_id, train_data):\n",
    "    \"\"\"Predict rating for a specific user-item pair - Fixed version\"\"\"\n",
    "    try:\n",
    "        # Check if user and item exist\n",
    "        if user_id not in train_data.user_ids:\n",
    "            return None\n",
    "        if item_id not in train_data.item_ids:\n",
    "            return None\n",
    "            \n",
    "        prediction = model.score(user_id, item_id)\n",
    "        return prediction if not np.isnan(prediction) else None\n",
    "    except Exception as e:\n",
    "        print(f\"Prediction error for user {user_id}, item {item_id}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test with actual users from the dataset\n",
    "try:\n",
    "    # Get some sample user IDs (AuthorIds) from your data\n",
    "    sample_users = list(train_data.user_ids)[:3]\n",
    "    \n",
    "    for user_id in sample_users:\n",
    "        print(f\"\\nTop-5 recommendations for user {user_id}:\")\n",
    "        recommendations = get_user_recommendations_fixed(svd_model, user_id, train_data, k=5)\n",
    "        \n",
    "        if recommendations:\n",
    "            for i, (item_id, score) in enumerate(recommendations, 1):\n",
    "                print(f\"  {i}. Recipe {item_id}: Score {score:.3f}\")\n",
    "        else:\n",
    "            print(\"  No recommendations available\")\n",
    "        \n",
    "        # Test rating prediction with an item the user has rated\n",
    "        user_items = train_data.matrix[train_data.uid_map[user_id]].indices\n",
    "        if len(user_items) > 0:\n",
    "            test_item_idx = user_items[0]\n",
    "            test_item_id = train_data.item_ids[test_item_idx]\n",
    "            predicted_rating = predict_rating_fixed(svd_model, user_id, test_item_id, train_data)\n",
    "            if predicted_rating is not None:\n",
    "                print(f\"  Predicted rating for recipe {test_item_id}: {predicted_rating:.3f}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Example usage error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d27a1f",
   "metadata": {},
   "source": [
    "## 7. Model Evaluation\n",
    "We evaluate the trained SVD model using standard metrics such as MAE, RMSE, Recall@20, and NDCG@20. The evaluation uses Cornac's BaseMethod.from_splits for a fair split between train and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36aacc0",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (1901396450.py, line 25)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[10], line 25\u001b[0;36m\u001b[0m\n\u001b[0;31m    met.NDCG(k=20)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "# 5. Model evaluation\n",
    "print(\"\\n=== Model Evaluation ===\")\n",
    "\n",
    "try:\n",
    "    # Convert train/test data to UIR tuples format\n",
    "    train_tuples = [(row.AuthorId, row.RecipeId, row.Rating) \n",
    "                   for row in train_dataset.itertuples(index=False)]\n",
    "    test_tuples = [(row.AuthorId, row.RecipeId, row.Rating) \n",
    "                  for row in test_dataset.itertuples(index=False)]\n",
    "    \n",
    "    # Create evaluation method using from_splits()\n",
    "    eval_method = BaseMethod.from_splits(\n",
    "        train_data=train_tuples,\n",
    "        test_data=test_tuples,\n",
    "        exclude_unknowns=True,\n",
    "        verbose=True,\n",
    "        seed=123\n",
    "    )\n",
    "    \n",
    "    # Define evaluation metrics\n",
    "    metrics_list = [\n",
    "        met.MAE(),\n",
    "        met.RMSE(),\n",
    "        met.Recall(k=20),\n",
    "        met.NDCG(k=20),\n",
    "        met.Precision(k=20),\n",
    "    ]\n",
    "    \n",
    "    # Evaluate the model\n",
    "    print(\"Running evaluation...\")\n",
    "    result, _ = eval_method.evaluate(  # Unpack the tuple\n",
    "        model=svd_model, \n",
    "        metrics=metrics_list, \n",
    "        user_based=True,\n",
    "    )\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\n=== Evaluation Results ===\")\n",
    "    # Print the entire result summary\n",
    "    print(result)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Evaluation error: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ada470c",
   "metadata": {},
   "source": [
    "## 8. Analyze SVD Factors\n",
    "We analyze the learned user and item factors, checking for NaN values and reporting the norms of the factor vectors to ensure the model has learned meaningful representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ea08b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVD Factor Analysis:\n",
      "User factors shape: (17748, 50)\n",
      "Item factors shape: (39057, 50)\n",
      "Average user factor norm: 1.1720\n",
      "Average item factor norm: 0.9435\n",
      "User factor norm range: [0.0595, 3.2946]\n",
      "Item factor norm range: [0.0537, 3.4499]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. Utility functions for analysis (Fixed)\n",
    "def analyze_svd_factors_fixed(model):\n",
    "    \"\"\"Analyze the learned factors - Fixed version\"\"\"\n",
    "    if hasattr(model, 'u_factors') and hasattr(model, 'i_factors'):\n",
    "        print(f\"\\nSVD Factor Analysis:\")\n",
    "        print(f\"User factors shape: {model.u_factors.shape}\")\n",
    "        print(f\"Item factors shape: {model.i_factors.shape}\")\n",
    "        \n",
    "        # Check for NaN values\n",
    "        user_nan_count = np.isnan(model.u_factors).sum()\n",
    "        item_nan_count = np.isnan(model.i_factors).sum()\n",
    "        \n",
    "        if user_nan_count > 0 or item_nan_count > 0:\n",
    "            print(f\"Warning: Found {user_nan_count} NaN values in user factors\")\n",
    "            print(f\"Warning: Found {item_nan_count} NaN values in item factors\")\n",
    "        else:\n",
    "            # Calculate norms only if no NaN values\n",
    "            user_factor_norms = np.linalg.norm(model.u_factors, axis=1)\n",
    "            item_factor_norms = np.linalg.norm(model.i_factors, axis=1)\n",
    "            \n",
    "            print(f\"Average user factor norm: {np.mean(user_factor_norms):.4f}\")\n",
    "            print(f\"Average item factor norm: {np.mean(item_factor_norms):.4f}\")\n",
    "            print(f\"User factor norm range: [{np.min(user_factor_norms):.4f}, {np.max(user_factor_norms):.4f}]\")\n",
    "            print(f\"Item factor norm range: [{np.min(item_factor_norms):.4f}, {np.max(item_factor_norms):.4f}]\")\n",
    "        \n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# Analyze the trained model\n",
    "analyze_svd_factors_fixed(svd_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48619500",
   "metadata": {},
   "source": [
    "## 9. Dataset Statistics\n",
    "We print summary statistics about the dataset, including the number of users, items, ratings, sparsity, and average ratings per user/item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204e7a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Dataset Statistics ===\n",
      "Number of users: 17748\n",
      "Number of items: 39057\n",
      "Number of ratings: 513384\n",
      "Sparsity: 0.9993\n",
      "Average ratings per user: 28.93\n",
      "Average ratings per item: 13.14\n"
     ]
    }
   ],
   "source": [
    "# 7. Data statistics\n",
    "print(\"\\n=== Dataset Statistics ===\")\n",
    "print(f\"Number of users: {len(train_data.user_ids)}\")\n",
    "print(f\"Number of items: {len(train_data.item_ids)}\")\n",
    "print(f\"Number of ratings: {train_data.num_ratings}\")\n",
    "print(f\"Sparsity: {1 - (train_data.num_ratings / (len(train_data.user_ids) * len(train_data.item_ids))):.4f}\")\n",
    "print(f\"Average ratings per user: {train_data.num_ratings / len(train_data.user_ids):.2f}\")\n",
    "print(f\"Average ratings per item: {train_data.num_ratings / len(train_data.item_ids):.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
