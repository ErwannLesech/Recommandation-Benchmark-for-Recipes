{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11c08f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install import_ipynb\n",
    "import import_ipynb \n",
    "import cornac\n",
    "from cornac.data import Dataset\n",
    "import cornac.metrics as met\n",
    "from cornac.eval_methods import BaseMethod\n",
    "from data_loader import DataLoader # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0279f9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/\"\n",
    "data_loader = DataLoader(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa8843df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(513384, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ReviewId</th>\n",
       "      <th>RecipeId</th>\n",
       "      <th>AuthorId</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>826743</td>\n",
       "      <td>3745</td>\n",
       "      <td>345380</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1247176</td>\n",
       "      <td>26217</td>\n",
       "      <td>406131</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1250914</td>\n",
       "      <td>17123</td>\n",
       "      <td>355582</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>183560</td>\n",
       "      <td>123283</td>\n",
       "      <td>58104</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1255493</td>\n",
       "      <td>110139</td>\n",
       "      <td>383795</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ReviewId  RecipeId  AuthorId  Rating\n",
       "0    826743      3745    345380       4\n",
       "1   1247176     26217    406131       1\n",
       "2   1250914     17123    355582       5\n",
       "3    183560    123283     58104       4\n",
       "4   1255493    110139    383795       5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset, test_dataset = data_loader.load_for_cornac(dataset_type='split')\n",
    "print(train_dataset.shape)\n",
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "402a2904",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cornac.models import ItemKNN\n",
    "from cornac.eval_methods import RatioSplit\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def train_item_knn(train_dataset, test_dataset, k_values=[5, 10, 20, 50], train_percentage=0.1, test_percentage=0.1, verbose=True):\n",
    "    \"\"\"\n",
    "    Train ItemKNN models for different k values and evaluate them.\n",
    "    Returns: (item_knn_models, item_knn_results)\n",
    "    \"\"\"\n",
    "    # Use a percentage of the dataset\n",
    "    train_sample = train_dataset.sample(frac=train_percentage, random_state=42)\n",
    "    test_sample = test_dataset.sample(frac=test_percentage, random_state=42)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Train dataset size: {train_sample.shape}\\nTest dataset size: {test_sample.shape}\")\n",
    "\n",
    "    from cornac.data import Dataset\n",
    "    cornac_train_dataset = Dataset.from_uir(train_sample[['AuthorId', 'RecipeId', 'Rating']].values.tolist(), seed=42)\n",
    "\n",
    "    import cornac.metrics as met\n",
    "    metrics = [\n",
    "        met.MSE(),\n",
    "        met.RMSE(),\n",
    "        met.MAE(),\n",
    "        met.Precision(k=10),\n",
    "        met.Recall(k=10),\n",
    "        met.NDCG(k=10),\n",
    "    ]\n",
    "    from cornac.eval_methods import BaseMethod\n",
    "    eval_method = BaseMethod.from_splits(train_sample[['AuthorId', 'RecipeId', 'Rating']].values, test_sample[['AuthorId', 'RecipeId', 'Rating']].values)\n",
    "\n",
    "    item_knn_models = {}\n",
    "    item_knn_results = []\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"ITEM-BASED COLLABORATIVE FILTERING (ItemKNN) EVALUATION\")\n",
    "        print(\"=\"*80)\n",
    "\n",
    "    for k in k_values:\n",
    "        if verbose:\n",
    "            print(f\"\\nTesting ItemKNN with k={k}...\")\n",
    "        item_knn = ItemKNN(k=k, similarity='cosine', verbose=verbose)\n",
    "        start_time = time.time()\n",
    "        item_knn.fit(cornac_train_dataset)\n",
    "        total_time = time.time() - start_time\n",
    "        # Evaluate metrics\n",
    "        results = eval_method.evaluate(item_knn, metrics=metrics, user_based=False)\n",
    "        model_result = {\n",
    "            'model': f'ItemKNN(k={k})',\n",
    "            'k': k,\n",
    "            'results': results,\n",
    "            'total_time': total_time,\n",
    "            'item_knn': item_knn\n",
    "        }\n",
    "        item_knn_models[k] = item_knn\n",
    "        item_knn_results.append(model_result)\n",
    "        if verbose:\n",
    "            print(f\"  Total time: {total_time:.2f}s\")\n",
    "    return item_knn_models, item_knn_results, train_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfaacb4d",
   "metadata": {},
   "source": [
    "# Diversified Recommendations: Maximal Marginal Relevance (MMR)\n",
    "\n",
    "In this section, we implement the Maximal Marginal Relevance (MMR) algorithm to diversify recommendations. MMR balances the utility (relevance) of recommended items with their diversity, using a parameter $\\alpha$ to control the trade-off. We compare the original recommendations from user-based and item-based collaborative filtering with the diversified recommendations and evaluate them using standard metrics (Precision@k, NDCG@k, Intra-list Diversity).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e50f916",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import import_ipynb\n",
    "\n",
    "def mmr_diversify(utility_scores, item_ids, similarity_matrix, k=10, alpha=0.5):\n",
    "    \"\"\"\n",
    "    MMR diversification for recommendations.\n",
    "    utility_scores: dict {item_id: utility}\n",
    "    item_ids: list of candidate item ids (sorted by utility)\n",
    "    similarity_matrix: 2D numpy array, item-item similarity (cosine)\n",
    "    k: number of items to recommend\n",
    "    alpha: trade-off between utility and diversity (0=utility only, 1=diversity only)\n",
    "    \"\"\"\n",
    "    selected = [item_ids[0]]  # Start with the most relevant item\n",
    "    candidates = set(item_ids[1:])\n",
    "    while len(selected) < k and candidates:\n",
    "        mmr_scores = []\n",
    "        for i in candidates:\n",
    "            utility = utility_scores[i]\n",
    "            # Diversity: min distance to already selected items\n",
    "            diversity = min(1 - similarity_matrix[i, j] for j in selected)\n",
    "            mmr_score = (1 - alpha) * utility + alpha * diversity\n",
    "            mmr_scores.append((i, mmr_score))\n",
    "        # Select item with highest MMR score\n",
    "        next_item = max(mmr_scores, key=lambda x: x[1])[0]\n",
    "        selected.append(next_item)\n",
    "        candidates.remove(next_item)\n",
    "    return selected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d66ae42",
   "metadata": {},
   "source": [
    "## How to Use MMR Diversification\n",
    "\n",
    "1. Generate a list of candidate recommendations and their utility scores using your user-based or item-based recommender.\n",
    "2. Compute or load the item-item similarity matrix (cosine similarity is common).\n",
    "3. Use the `mmr_diversify` function to select a diversified top-k list.\n",
    "4. Evaluate the diversified list using metrics such as Precision@k, NDCG@k, and Intra-list Diversity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c42395",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abel/epita/recomendation_system/venv/lib/python3.12/site-packages/cornac/models/recommender.py:322: UserWarning: Model is already fitted. Re-fitting will overwrite the previous model.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Train the ItemKNN model (or load if already trained)\n",
    "item_knn_models, item_knn_results, train_sample = train_item_knn(\n",
    "    train_dataset, test_dataset, k_values=[10], train_percentage=0.1, test_percentage=0.1, verbose=False)\n",
    "item_knn = item_knn_models[10]  # Use k=10 for demonstration\n",
    "\n",
    "# Get the original user ID (if needed)\n",
    "user_id = item_knn.user_ids[0]\n",
    "\n",
    "# Get top-N recommendations (internal item indices)\n",
    "top_items = item_knn.recommend(user_id, k=item_knn.total_items)\n",
    "\n",
    "# Compute utility scores using internal indices\n",
    "utility_scores = {item: item_knn.score(user_id, item) for item in top_items}\n",
    "\n",
    "# Get the item-item similarity matrix from the model (cosine similarity)\n",
    "if hasattr(item_knn, 'sim'):\n",
    "    similarity_matrix = item_knn.sim\n",
    "elif hasattr(item_knn, '_sim'):\n",
    "    similarity_matrix = item_knn._sim\n",
    "else:\n",
    "    raise AttributeError(\"ItemKNN model does not have a similarity matrix attribute ('sim' or '_sim').\")\n",
    "\n",
    "# Prepare candidate item list (not yet rated by the user)\n",
    "rated_items = set(train_sample[(train_sample['AuthorId'] == user_id)]['RecipeId'])\n",
    "candidate_items = [item for item in top_items if item not in rated_items]\n",
    "\n",
    "# Sort candidate items by utility (already sorted by recommend, but for safety)\n",
    "item_ids = sorted(candidate_items, key=lambda i: utility_scores[i], reverse=True)\n",
    "\n",
    "N = 10\n",
    "alpha = 0.5\n",
    "mmr_topN = mmr_diversify(utility_scores, item_ids, similarity_matrix, k=N, alpha=alpha)\n",
    "\n",
    "print(\"MMR Diversified Recommendations:\", mmr_topN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774440f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
