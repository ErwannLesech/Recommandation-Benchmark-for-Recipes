{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11c08f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abel/epita/recomendation_system/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# %pip install import_ipynb\n",
    "import import_ipynb \n",
    "import cornac\n",
    "from cornac.data import Dataset\n",
    "import cornac.metrics as met\n",
    "from cornac.eval_methods import BaseMethod\n",
    "from data_loader import DataLoader # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0279f9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/\"\n",
    "data_loader = DataLoader(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa8843df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(513384, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ReviewId</th>\n",
       "      <th>RecipeId</th>\n",
       "      <th>AuthorId</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>826743</td>\n",
       "      <td>3745</td>\n",
       "      <td>345380</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1247176</td>\n",
       "      <td>26217</td>\n",
       "      <td>406131</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1250914</td>\n",
       "      <td>17123</td>\n",
       "      <td>355582</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>183560</td>\n",
       "      <td>123283</td>\n",
       "      <td>58104</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1255493</td>\n",
       "      <td>110139</td>\n",
       "      <td>383795</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ReviewId  RecipeId  AuthorId  Rating\n",
       "0    826743      3745    345380       4\n",
       "1   1247176     26217    406131       1\n",
       "2   1250914     17123    355582       5\n",
       "3    183560    123283     58104       4\n",
       "4   1255493    110139    383795       5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset, test_dataset = data_loader.load_for_cornac(dataset_type='split')\n",
    "print(train_dataset.shape)\n",
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "402a2904",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cornac.models import ItemKNN\n",
    "from cornac.eval_methods import RatioSplit\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def train_item_knn(train_dataset, test_dataset, k_values=[5, 10, 20, 50], train_percentage=0.1, test_percentage=0.1, verbose=True, stratify_by='item'):\n",
    "    \"\"\"\n",
    "    Train ItemKNN models for different k values and evaluate them.\n",
    "    stratify_by: 'user', 'item', or None. If 'item', ensures all items are represented in train/test splits.\n",
    "    Returns: (item_knn_models, item_knn_results, train_sample)\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    # Stratified sampling\n",
    "    if stratify_by == 'user':\n",
    "        train_sample = train_dataset.groupby('AuthorId', group_keys=False).apply(\n",
    "            lambda x: x.sample(frac=train_percentage, random_state=42) if len(x) > 1 else x\n",
    "        ).reset_index(drop=True)\n",
    "        test_sample = test_dataset.groupby('AuthorId', group_keys=False).apply(\n",
    "            lambda x: x.sample(frac=test_percentage, random_state=42) if len(x) > 1 else x\n",
    "        ).reset_index(drop=True)\n",
    "    elif stratify_by == 'item':\n",
    "        train_sample = train_dataset.groupby('RecipeId', group_keys=False).apply(\n",
    "            lambda x: x.sample(frac=train_percentage, random_state=42) if len(x) > 1 else x\n",
    "        ).reset_index(drop=True)\n",
    "        test_sample = test_dataset.groupby('RecipeId', group_keys=False).apply(\n",
    "            lambda x: x.sample(frac=test_percentage, random_state=42) if len(x) > 1 else x\n",
    "        ).reset_index(drop=True)\n",
    "    else:\n",
    "        train_sample = train_dataset.sample(frac=train_percentage, random_state=42)\n",
    "        test_sample = test_dataset.sample(frac=test_percentage, random_state=42)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Train dataset size: {train_sample.shape}\\nTest dataset size: {test_sample.shape}\")\n",
    "\n",
    "    from cornac.data import Dataset\n",
    "    cornac_train_dataset = Dataset.from_uir(train_sample[['AuthorId', 'RecipeId', 'Rating']].values.tolist(), seed=42)\n",
    "\n",
    "    import cornac.metrics as met\n",
    "    metrics = [\n",
    "        met.MSE(),\n",
    "        met.RMSE(),\n",
    "        met.MAE(),\n",
    "        met.Precision(k=10),\n",
    "        met.Recall(k=10),\n",
    "        met.NDCG(k=10),\n",
    "    ]\n",
    "    from cornac.eval_methods import BaseMethod\n",
    "    eval_method = BaseMethod.from_splits(train_sample[['AuthorId', 'RecipeId', 'Rating']].values, test_sample[['AuthorId', 'RecipeId', 'Rating']].values)\n",
    "\n",
    "    item_knn_models = {}\n",
    "    item_knn_results = []\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"ITEM-BASED COLLABORATIVE FILTERING (ItemKNN) EVALUATION\")\n",
    "        print(\"=\"*80)\n",
    "\n",
    "    for k in k_values:\n",
    "        if verbose:\n",
    "            print(f\"\\nTesting ItemKNN with k={k}...\")\n",
    "        item_knn = ItemKNN(k=k, similarity='cosine', verbose=verbose)\n",
    "        start_time = time.time()\n",
    "        item_knn.fit(cornac_train_dataset)\n",
    "        total_time = time.time() - start_time\n",
    "        # Evaluate metrics\n",
    "        results = eval_method.evaluate(item_knn, metrics=metrics, user_based=False)\n",
    "        model_result = {\n",
    "            'model': f'ItemKNN(k={k})',\n",
    "            'k': k,\n",
    "            'results': results,\n",
    "            'total_time': total_time,\n",
    "            'item_knn': item_knn\n",
    "        }\n",
    "        item_knn_models[k] = item_knn\n",
    "        item_knn_results.append(model_result)\n",
    "        if verbose:\n",
    "            print(f\"  Total time: {total_time:.2f}s\")\n",
    "    return item_knn_models, item_knn_results, train_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfaacb4d",
   "metadata": {},
   "source": [
    "# Diversified Recommendations: Maximal Marginal Relevance (MMR)\n",
    "\n",
    "In this section, we implement the Maximal Marginal Relevance (MMR) algorithm to diversify recommendations. MMR balances the utility (relevance) of recommended items with their diversity, using a parameter $\\alpha$ to control the trade-off. We compare the original recommendations from user-based and item-based collaborative filtering with the diversified recommendations and evaluate them using standard metrics (Precision@k, NDCG@k, Intra-list Diversity).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c42395",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abel/epita/recomendation_system/venv/lib/python3.12/site-packages/cornac/models/recommender.py:322: UserWarning: Model is already fitted. Re-fitting will overwrite the previous model.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Train the ItemKNN model (or load if already trained)\n",
    "item_knn_models, item_knn_results, train_sample = train_item_knn(\n",
    "    train_dataset, test_dataset, k_values=[10], train_percentage=0.5, test_percentage=0.1, verbose=False, stratify_by=None)\n",
    "item_knn = item_knn_models[10]  # Use k=10 for demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "774440f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diversified Recommendations (MMR):\n",
      "Item ID: 3400, Utility Score: 5.0000\n",
      "Item ID: 7682, Utility Score: 5.0000\n",
      "Item ID: 8494, Utility Score: 5.0000\n",
      "Item ID: 8603, Utility Score: 5.0000\n",
      "Item ID: 12656, Utility Score: 5.0000\n",
      "Item ID: 17232, Utility Score: 5.0000\n",
      "Item ID: 18481, Utility Score: 5.0000\n",
      "Item ID: 26121, Utility Score: 5.0000\n",
      "Item ID: 33242, Utility Score: 5.0000\n",
      "Item ID: 2670, Utility Score: 5.0000\n"
     ]
    }
   ],
   "source": [
    "# Now we try to diversify the recommendations using MMR\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def mmr_diversify(utility_scores, item_ids, similarity_matrix, k=10, alpha=0.5, item_id_to_index=None):\n",
    "    selected = [item_ids[0]]\n",
    "    candidates = set(item_ids[1:])\n",
    "    while len(selected) < k and candidates:\n",
    "        mmr_scores = []\n",
    "        for i in candidates:\n",
    "            utility = utility_scores[i]\n",
    "            i_idx = item_id_to_index[i]\n",
    "            diversity = min(1 - similarity_matrix[i_idx, item_id_to_index[j]] for j in selected)\n",
    "            mmr_score = (1 - alpha) * utility + alpha * diversity\n",
    "            mmr_scores.append((i, mmr_score))\n",
    "        next_item = max(mmr_scores, key=lambda x: x[1])[0]\n",
    "        selected.append(next_item)\n",
    "        candidates.remove(next_item)\n",
    "    return selected\n",
    "\n",
    "# Pick a user ID that is in the model and can be scored\n",
    "for candidate_user in item_knn.user_ids:\n",
    "    try:\n",
    "        _ = item_knn.score(candidate_user, item_knn.item_ids[0])\n",
    "        user_id = candidate_user\n",
    "        break\n",
    "    except Exception:\n",
    "        continue\n",
    "else:\n",
    "    raise RuntimeError(\"No valid user found for scoring.\")\n",
    "\n",
    "# Get all items known to the model that can be scored for this user\n",
    "utility_scores = {}\n",
    "for item in item_knn.item_ids:\n",
    "    try:\n",
    "        utility_scores[item] = item_knn.score(user_id, item)\n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "# Recompute the similarity matrix using the train_sample\n",
    "item_user_matrix = train_sample.pivot_table(index='RecipeId', columns='AuthorId', values='Rating', fill_value=0)\n",
    "similarity_matrix = cosine_similarity(item_user_matrix)\n",
    "item_id_to_index = {item_id: idx for idx, item_id in enumerate(item_user_matrix.index)}\n",
    "\n",
    "# Get items not yet rated by the user\n",
    "rated_items = set(train_sample[train_sample['AuthorId'] == user_id]['RecipeId'])\n",
    "candidate_items = [item for item in item_user_matrix.index if item not in rated_items and item in utility_scores]\n",
    "\n",
    "# Sort candidate items by utility\n",
    "item_ids = sorted(candidate_items, key=lambda x: utility_scores[x], reverse=True)\n",
    "\n",
    "# Perform MMR diversification\n",
    "k = 10  # Number of items to recommend\n",
    "alpha = 0.5  # Trade-off between utility and diversity\n",
    "diversified_recommendations = mmr_diversify(utility_scores, item_ids, similarity_matrix, k=k, alpha=alpha, item_id_to_index=item_id_to_index)\n",
    "# Print the diversified recommendations\n",
    "print(\"Diversified Recommendations (MMR):\")\n",
    "for item in diversified_recommendations:\n",
    "    print(f\"Item ID: {item}, Utility Score: {utility_scores[item]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3a8c6db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original Recommendations:\n",
      "Item ID: 78284, Utility Score: No score available for this item\n",
      "Item ID: 244058, Utility Score: No score available for this item\n",
      "Item ID: 75453, Utility Score: No score available for this item\n",
      "Item ID: 373159, Utility Score: No score available for this item\n",
      "Item ID: 56471, Utility Score: No score available for this item\n",
      "Item ID: 13244, Utility Score: 4.5000\n",
      "Item ID: 378571, Utility Score: No score available for this item\n",
      "Item ID: 252536, Utility Score: No score available for this item\n",
      "Item ID: 72614, Utility Score: No score available for this item\n",
      "Item ID: 64599, Utility Score: No score available for this item\n"
     ]
    }
   ],
   "source": [
    "# compare diversity reco with the original recommendations\n",
    "original_recommendations = item_knn.recommend(user_id, k=k)\n",
    "print(\"\\nOriginal Recommendations:\")\n",
    "for item in original_recommendations:\n",
    "    try:\n",
    "        score = item_knn.score(user_id, item)\n",
    "        print(f\"Item ID: {item}, Utility Score: {score:.4f}\")\n",
    "    except Exception:\n",
    "        # Skip items that cannot be scored\n",
    "        print(f\"Item ID: {item}, Utility Score: No score available for this item\")\n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
