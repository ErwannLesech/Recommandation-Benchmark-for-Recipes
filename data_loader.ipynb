{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee1f28d8",
   "metadata": {},
   "source": [
    "# Data Loader\n",
    "\n",
    "This file aims to add utils functions and classes to load and handle data of the project.\n",
    "\n",
    "### Class to import in other files to load datasets of the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1da78368",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from typing import Dict, List, Optional, Tuple, Any\n",
    "import numpy as np\n",
    "\n",
    "class DataLoader:\n",
    "    \"\"\"\n",
    "    Flexible DataLoader class for loading various datasets optimized for different \n",
    "    recommender system libraries (Cornac, Surprise, scikit-learn, etc.)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_folder: str):\n",
    "        self.data_folder = data_folder\n",
    "        \n",
    "        # Core dataset files\n",
    "        self.files = {\n",
    "            # Original datasets\n",
    "            \"reviews\": \"reviews.csv\",\n",
    "            \"recipes\": \"recipes.csv\",\n",
    "            \"clean_reviews\": \"clean_reviews.csv\",\n",
    "            \n",
    "            # K-core filtered datasets for Cornac\n",
    "            \"reviews_k6\": \"reviews_dataset_k6.csv\",\n",
    "            \"train_k6\": \"reviews_train_k6.csv\", \n",
    "            \"test_k6\": \"reviews_test_k6.csv\",\n",
    "        }\n",
    "        \n",
    "        self.paths = {k: os.path.join(self.data_folder, v) for k, v in self.files.items()}\n",
    "        \n",
    "        # Library-specific configurations\n",
    "        self.library_configs = {\n",
    "            'cornac': {\n",
    "                'required_columns': ['AuthorId', 'RecipeId', 'Rating'],\n",
    "                'user_col': 'AuthorId',\n",
    "                'item_col': 'RecipeId', \n",
    "                'rating_col': 'Rating',\n",
    "                'default_dataset': 'reviews_k6'\n",
    "            }\n",
    "        }\n",
    "\n",
    "    # ==================== BASIC LOADING METHODS ====================\n",
    "    \n",
    "    def load_raw_reviews(self) -> pd.DataFrame:\n",
    "        \"\"\"Load original reviews dataset\"\"\"\n",
    "        return pd.read_csv(self.paths[\"reviews\"])\n",
    "\n",
    "    def load_recipes(self) -> pd.DataFrame:\n",
    "        \"\"\"Load recipes dataset\"\"\"\n",
    "        return pd.read_csv(self.paths[\"recipes\"])\n",
    "    \n",
    "    def load_reviews(self) -> pd.DataFrame:\n",
    "        \"\"\"Load cleaned reviews dataset\"\"\"\n",
    "        if os.path.exists(self.paths[\"clean_reviews\"]):\n",
    "            return pd.read_csv(self.paths[\"clean_reviews\"])\n",
    "        else:\n",
    "            return self.load_reviews()  # Fallback to original reviews\n",
    "\n",
    "    # ==================== K-CORE FILTERED DATASETS ====================\n",
    "    \n",
    "    def load_reviews_k6(self) -> pd.DataFrame:\n",
    "        \"\"\"Load k-core filtered dataset (K=6) - optimized for Cornac\"\"\"\n",
    "        return pd.read_csv(self.paths[\"reviews_k6\"])\n",
    "    \n",
    "    def load_train_k6(self) -> pd.DataFrame:\n",
    "        \"\"\"Load k-core filtered training set (K=6)\"\"\"\n",
    "        return pd.read_csv(self.paths[\"train_k6\"])\n",
    "    \n",
    "    def load_test_k6(self) -> pd.DataFrame:\n",
    "        \"\"\"Load k-core filtered test set (K=6)\"\"\"\n",
    "        return pd.read_csv(self.paths[\"test_k6\"])\n",
    "    \n",
    "    def load_k6_split(self) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "        \"\"\"Load both k-core filtered train and test sets\"\"\"\n",
    "        return self.load_train_k6(), self.load_test_k6()\n",
    "\n",
    "    # ==================== LIBRARY-SPECIFIC METHODS ====================\n",
    "    \n",
    "    def load_for_cornac(self, dataset_type: str = 'full', return_mappings: bool = False) -> Any:\n",
    "        \"\"\"\n",
    "        Load data optimized for Cornac library\n",
    "        \n",
    "        Args:\n",
    "            dataset_type: 'full', 'train', 'test', or 'split'\n",
    "            return_mappings: If True, also return user/item ID mappings\n",
    "            \n",
    "        Returns:\n",
    "            Cornac-compatible data format\n",
    "        \"\"\"\n",
    "        config = self.library_configs['cornac']\n",
    "        \n",
    "        if dataset_type == 'full':\n",
    "            df = self.load_reviews_k6()\n",
    "        elif dataset_type == 'train':\n",
    "            df = self.load_train_k6()\n",
    "        elif dataset_type == 'test':\n",
    "            df = self.load_test_k6()\n",
    "        elif dataset_type == 'split':\n",
    "            return self.load_k6_split()\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown dataset_type: {dataset_type}\")\n",
    "        \n",
    "        # Ensure required columns exist\n",
    "        self._validate_columns(df, config['required_columns'])\n",
    "        \n",
    "        if return_mappings:\n",
    "            user_mapping = {user: idx for idx, user in enumerate(df[config['user_col']].unique())}\n",
    "            item_mapping = {item: idx for idx, item in enumerate(df[config['item_col']].unique())}\n",
    "            return df, user_mapping, item_mapping\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    # ==================== UTILITY METHODS ====================\n",
    "    \n",
    "    def get_available_files(self) -> List[str]:\n",
    "        \"\"\"Get list of available dataset files\"\"\"\n",
    "        available = []\n",
    "        for key, filename in self.files.items():\n",
    "            if os.path.exists(self.paths[key]):\n",
    "                available.append(f\"{key}: {filename}\")\n",
    "        return available\n",
    "    \n",
    "    def get_dataset_info(self, dataset_name: str) -> Dict[str, Any]:\n",
    "        \"\"\"Get information about a specific dataset\"\"\"\n",
    "        if dataset_name not in self.files:\n",
    "            raise ValueError(f\"Unknown dataset: {dataset_name}\")\n",
    "        \n",
    "        path = self.paths[dataset_name]\n",
    "        if not os.path.exists(path):\n",
    "            return {\"exists\": False, \"path\": path}\n",
    "        \n",
    "        # Load dataset to get info\n",
    "        df = pd.read_csv(path)\n",
    "        \n",
    "        info = {\n",
    "            \"exists\": True,\n",
    "            \"path\": path,\n",
    "            \"shape\": df.shape,\n",
    "            \"columns\": list(df.columns),\n",
    "            \"file_size_mb\": os.path.getsize(path) / (1024 * 1024)\n",
    "        }\n",
    "        \n",
    "        # Add specific info if it's a reviews dataset\n",
    "        if any(col in df.columns for col in ['AuthorId', 'RecipeId', 'Rating']):\n",
    "            info.update({\n",
    "                \"n_users\": df['AuthorId'].nunique() if 'AuthorId' in df.columns else None,\n",
    "                \"n_items\": df['RecipeId'].nunique() if 'RecipeId' in df.columns else None,\n",
    "                \"n_ratings\": len(df),\n",
    "                \"rating_range\": (df['Rating'].min(), df['Rating'].max()) if 'Rating' in df.columns else None,\n",
    "                \"sparsity\": self._calculate_sparsity(df) if all(col in df.columns for col in ['AuthorId', 'RecipeId']) else None\n",
    "            })\n",
    "        \n",
    "        return info\n",
    "    \n",
    "    def list_datasets_by_library(self, library: str) -> Dict[str, Any]:\n",
    "        \"\"\"List recommended datasets for a specific library\"\"\"\n",
    "        if library not in self.library_configs:\n",
    "            raise ValueError(f\"Unknown library: {library}. Supported: {list(self.library_configs.keys())}\")\n",
    "        \n",
    "        config = self.library_configs[library]\n",
    "        recommended_datasets = []\n",
    "        \n",
    "        # Check which datasets are compatible\n",
    "        for dataset_name in ['reviews_k6', 'train_k6', 'test_k6']:\n",
    "            if os.path.exists(self.paths[dataset_name]):\n",
    "                info = self.get_dataset_info(dataset_name)\n",
    "                if all(col in info['columns'] for col in config['required_columns']):\n",
    "                    recommended_datasets.append({\n",
    "                        'name': dataset_name,\n",
    "                        'info': info,\n",
    "                        'recommended_for': ['training', 'evaluation'] if 'train' in dataset_name or 'test' in dataset_name else ['full_dataset']\n",
    "                    })\n",
    "        \n",
    "        return {\n",
    "            'library': library,\n",
    "            'config': config,\n",
    "            'recommended_datasets': recommended_datasets\n",
    "        }\n",
    "\n",
    "    # ==================== PRIVATE HELPER METHODS ====================\n",
    "    \n",
    "    def _validate_columns(self, df: pd.DataFrame, required_cols: List[str]) -> None:\n",
    "        \"\"\"Validate that DataFrame has required columns\"\"\"\n",
    "        missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "        if missing_cols:\n",
    "            raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
    "    \n",
    "    \n",
    "    def _calculate_sparsity(self, df: pd.DataFrame) -> float:\n",
    "        \"\"\"Calculate sparsity of the user-item matrix\"\"\"\n",
    "        n_users = df['AuthorId'].nunique()\n",
    "        n_items = df['RecipeId'].nunique()\n",
    "        n_ratings = len(df)\n",
    "        possible_ratings = n_users * n_items\n",
    "        return (1 - n_ratings / possible_ratings) * 100\n",
    "    \n",
    "    \n",
    "    # ==================== HELP METHOD ====================\n",
    "    \n",
    "    def help(self) -> None:\n",
    "        \"\"\"\n",
    "        Display a comprehensive help guide for the DataLoader class\n",
    "        \"\"\"\n",
    "        print(\"=\" * 100)\n",
    "        print(\"ğŸš€ DataLoader Class - Comprehensive Help Guide\")\n",
    "        print(\"=\" * 100)\n",
    "        \n",
    "        print(\"\\nğŸ“‹ OVERVIEW:\")\n",
    "        print(\"-\" * 50)\n",
    "        print(\"Flexible DataLoader for loading datasets optimized for different recommender system libraries\")\n",
    "        print(\"Supports: Cornac and custom usage\")\n",
    "        print(f\"Data folder: {self.data_folder}\")\n",
    "        \n",
    "        print(\"\\nğŸ“ AVAILABLE DATASETS:\")\n",
    "        print(\"-\" * 50)\n",
    "        available = self.get_available_files()\n",
    "        if available:\n",
    "            for file_info in available:\n",
    "                print(f\"  âœ… {file_info}\")\n",
    "        else:\n",
    "            print(\"  âŒ No datasets found in the data folder\")\n",
    "        \n",
    "        print(\"\\nğŸ”§ BASIC LOADING METHODS:\")\n",
    "        print(\"-\" * 50)\n",
    "        basic_methods = [\n",
    "            (\"load_reviews()\", \"Load original reviews dataset\"),\n",
    "            (\"load_recipes()\", \"Load recipes dataset\"),\n",
    "            (\"load_clean_reviews()\", \"Load cleaned reviews dataset\")\n",
    "        ]\n",
    "        for method, description in basic_methods:\n",
    "            print(f\"  ğŸ“„ {method:<25} â†’ {description}\")\n",
    "        \n",
    "        print(\"\\nâ­ K-CORE FILTERED DATASETS (Recommended for Cornac):\")\n",
    "        print(\"-\" * 50)\n",
    "        kcore_methods = [\n",
    "            (\"load_reviews_k6()\", \"Load k-core filtered dataset (K=6) - optimized for Cornac\"),\n",
    "            (\"load_train_k6()\", \"Load k-core filtered training set (K=6)\"),\n",
    "            (\"load_test_k6()\", \"Load k-core filtered test set (K=6)\"),\n",
    "            (\"load_k6_split()\", \"Load both k-core filtered train and test sets\")\n",
    "        ]\n",
    "        for method, description in kcore_methods:\n",
    "            print(f\"  â­ {method:<25} â†’ {description}\")\n",
    "        \n",
    "        print(\"\\nğŸ”„ LEGACY METHODS (Backward Compatibility):\")\n",
    "        print(\"-\" * 50)\n",
    "        legacy_methods = [\n",
    "            (\"load_train_reviews()\", \"Load legacy training reviews\"),\n",
    "            (\"load_test_reviews()\", \"Load legacy test reviews\"),\n",
    "            (\"load_reviews_knn()\", \"Load legacy KNN filtered reviews\"),\n",
    "            (\"load_train_knn_reviews()\", \"Load legacy KNN training reviews\"),\n",
    "            (\"load_test_knn_reviews()\", \"Load legacy KNN test reviews\")\n",
    "        ]\n",
    "        for method, description in legacy_methods:\n",
    "            print(f\"  ğŸ”„ {method:<25} â†’ {description}\")\n",
    "        \n",
    "        print(\"\\nğŸ¯ LIBRARY-SPECIFIC METHODS:\")\n",
    "        print(\"-\" * 50)\n",
    "        library_methods = [\n",
    "            (\"load_for_cornac()\", \"Load data optimized for Cornac library\"),\n",
    "            (\"load_for_surprise()\", \"Load data optimized for Surprise library\"),\n",
    "            (\"load_for_sklearn()\", \"Load data optimized for scikit-learn\")\n",
    "        ]\n",
    "        for method, description in library_methods:\n",
    "            print(f\"  ğŸ¯ {method:<25} â†’ {description}\")\n",
    "        \n",
    "        print(\"\\nğŸ› ï¸  UTILITY METHODS:\")\n",
    "        print(\"-\" * 50)\n",
    "        utility_methods = [\n",
    "            (\"get_available_files()\", \"Get list of available dataset files\"),\n",
    "            (\"get_dataset_info(name)\", \"Get detailed information about a specific dataset\"),\n",
    "            (\"list_datasets_by_library(lib)\", \"List recommended datasets for a specific library\"),\n",
    "            (\"help()\", \"Display this help guide\")\n",
    "        ]\n",
    "        for method, description in utility_methods:\n",
    "            print(f\"  ğŸ› ï¸  {method:<25} â†’ {description}\")\n",
    "        \n",
    "        print(\"\\nğŸ’¡ QUICK START EXAMPLES:\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        print(\"\\n  ğŸ”¹ For Cornac:\")\n",
    "        print(\"     train_df, test_df = loader.load_for_cornac(dataset_type='split')\")\n",
    "        \n",
    "        print(\"\\n  ğŸ”¹ Get dataset info:\")\n",
    "        print(\"     info = loader.get_dataset_info('reviews_k6')\")\n",
    "        \n",
    "        print(\"\\n  ğŸ”¹ Check library compatibility:\")\n",
    "        print(\"     recommendations = loader.list_datasets_by_library('cornac')\")\n",
    "        \n",
    "        print(\"\\nğŸ“Š DATASET PARAMETERS:\")\n",
    "        print(\"-\" * 50)\n",
    "        print(\"  dataset_type options: 'full', 'train', 'test', 'split'\")\n",
    "        print(\"  return_format options (sklearn): 'matrix', 'dataframe', 'arrays'\")\n",
    "        print(\"  Supported libraries: 'cornac', 'surprise', 'sklearn'\")\n",
    "        \n",
    "        # Show current dataset stats if available\n",
    "        try:\n",
    "            if os.path.exists(self.paths['reviews_k6']):\n",
    "                info = self.get_dataset_info('reviews_k6')\n",
    "                print(f\"\\nğŸ“ˆ CURRENT K-CORE DATASET STATS:\")\n",
    "                print(\"-\" * 50)\n",
    "                print(f\"  ğŸ‘¥ Users: {info.get('n_users', 'N/A'):,}\")\n",
    "                print(f\"  ğŸ³ Recipes: {info.get('n_items', 'N/A'):,}\")\n",
    "                print(f\"  â­ Ratings: {info.get('n_ratings', 'N/A'):,}\")\n",
    "                print(f\"  ğŸ“ Sparsity: {info.get('sparsity', 'N/A'):.2f}%\")\n",
    "                print(f\"  ğŸ’¾ File size: {info.get('file_size_mb', 'N/A'):.1f} MB\")\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 100)\n",
    "        print(\"ğŸ‰ Ready to load data for your recommender system experiments!\")\n",
    "        print(\"ğŸ’¬ Use loader.help() anytime to see this guide again.\")\n",
    "        print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9094c90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# ==================== USAGE EXAMPLES ====================\\n\\n# Initialize the DataLoader\\ndata_folder = \"data\"  # Adjust path as needed\\nloader = DataLoader(data_folder)\\n\\nprint(\"=\" * 80)\\nprint(\"DATALOADER USAGE EXAMPLES\")\\nprint(\"=\" * 80)\\n\\n# 1. Check available datasets\\nprint(\"\\n1. Available datasets:\")\\nprint(\"-\" * 40)\\navailable_files = loader.get_available_files()\\nfor file in available_files:\\n    print(f\"  âœ“ {file}\")\\n\\n# 2. Load k-core filtered dataset for Cornac\\nprint(\"\\n2. Loading data for Cornac:\")\\nprint(\"-\" * 40)\\ntry:\\n    # Load full k-core dataset\\n    cornac_data = loader.load_for_cornac(dataset_type=\\'full\\')\\n    print(f\"  âœ“ Full dataset loaded: {cornac_data.shape}\")\\n    print(f\"    Users: {cornac_data[\\'AuthorId\\'].nunique():,}\")\\n    print(f\"    Recipes: {cornac_data[\\'RecipeId\\'].nunique():,}\")\\n    print(f\"    Ratings: {len(cornac_data):,}\")\\n    \\n    # Load train/test split\\n    train_data, test_data = loader.load_for_cornac(dataset_type=\\'split\\')\\n    print(f\"  âœ“ Train/Test split loaded:\")\\n    print(f\"    Train: {train_data.shape}\")\\n    print(f\"    Test: {test_data.shape}\")\\n    \\nexcept Exception as e:\\n    print(f\"  âœ— Error loading Cornac data: {e}\")\\n\\n# 5. Get dataset information\\nprint(\"\\n5. Dataset information:\")\\nprint(\"-\" * 40)\\ntry:\\n    info = loader.get_dataset_info(\\'reviews_k6\\')\\n    print(f\"  âœ“ K6 dataset info:\")\\n    print(f\"    Shape: {info.get(\\'shape\\', \\'N/A\\')}\")\\n    print(f\"    Users: {info.get(\\'n_users\\', \\'N/A\\'):,}\")\\n    print(f\"    Items: {info.get(\\'n_items\\', \\'N/A\\'):,}\")\\n    print(f\"    Ratings: {info.get(\\'n_ratings\\', \\'N/A\\'):,}\")\\n    print(f\"    Sparsity: {info.get(\\'sparsity\\', \\'N/A\\'):.2f}%\")\\n    print(f\"    File size: {info.get(\\'file_size_mb\\', \\'N/A\\'):.1f} MB\")\\nexcept Exception as e:\\n    print(f\"  âœ— Error getting dataset info: {e}\")\\n\\n# 6. Library-specific recommendations\\nprint(\"\\n6. Library-specific recommendations:\")\\nprint(\"-\" * 40)\\nfor library in [\\'cornac\\']:\\n    try:\\n        recommendations = loader.list_datasets_by_library(library)\\n        print(f\"  âœ“ {library.upper()}:\")\\n        print(f\"    Default dataset: {recommendations[\\'config\\'][\\'default_dataset\\']}\")\\n        print(f\"    Available datasets: {len(recommendations[\\'recommended_datasets\\'])}\")\\n    except Exception as e:\\n        print(f\"  âœ— Error getting {library} recommendations: {e}\")\\n\\nprint(\"\\n\" + \"=\" * 80)\\nprint(\"DataLoader ready for use! ğŸš€\")\\nprint(\"=\" * 80)'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# ==================== USAGE EXAMPLES ====================\n",
    "\n",
    "# Initialize the DataLoader\n",
    "data_folder = \"data\"  # Adjust path as needed\n",
    "loader = DataLoader(data_folder)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"DATALOADER USAGE EXAMPLES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 1. Check available datasets\n",
    "print(\"\\n1. Available datasets:\")\n",
    "print(\"-\" * 40)\n",
    "available_files = loader.get_available_files()\n",
    "for file in available_files:\n",
    "    print(f\"  âœ“ {file}\")\n",
    "\n",
    "# 2. Load k-core filtered dataset for Cornac\n",
    "print(\"\\n2. Loading data for Cornac:\")\n",
    "print(\"-\" * 40)\n",
    "try:\n",
    "    # Load full k-core dataset\n",
    "    cornac_data = loader.load_for_cornac(dataset_type='full')\n",
    "    print(f\"  âœ“ Full dataset loaded: {cornac_data.shape}\")\n",
    "    print(f\"    Users: {cornac_data['AuthorId'].nunique():,}\")\n",
    "    print(f\"    Recipes: {cornac_data['RecipeId'].nunique():,}\")\n",
    "    print(f\"    Ratings: {len(cornac_data):,}\")\n",
    "    \n",
    "    # Load train/test split\n",
    "    train_data, test_data = loader.load_for_cornac(dataset_type='split')\n",
    "    print(f\"  âœ“ Train/Test split loaded:\")\n",
    "    print(f\"    Train: {train_data.shape}\")\n",
    "    print(f\"    Test: {test_data.shape}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"  âœ— Error loading Cornac data: {e}\")\n",
    "\n",
    "# 5. Get dataset information\n",
    "print(\"\\n5. Dataset information:\")\n",
    "print(\"-\" * 40)\n",
    "try:\n",
    "    info = loader.get_dataset_info('reviews_k6')\n",
    "    print(f\"  âœ“ K6 dataset info:\")\n",
    "    print(f\"    Shape: {info.get('shape', 'N/A')}\")\n",
    "    print(f\"    Users: {info.get('n_users', 'N/A'):,}\")\n",
    "    print(f\"    Items: {info.get('n_items', 'N/A'):,}\")\n",
    "    print(f\"    Ratings: {info.get('n_ratings', 'N/A'):,}\")\n",
    "    print(f\"    Sparsity: {info.get('sparsity', 'N/A'):.2f}%\")\n",
    "    print(f\"    File size: {info.get('file_size_mb', 'N/A'):.1f} MB\")\n",
    "except Exception as e:\n",
    "    print(f\"  âœ— Error getting dataset info: {e}\")\n",
    "\n",
    "# 6. Library-specific recommendations\n",
    "print(\"\\n6. Library-specific recommendations:\")\n",
    "print(\"-\" * 40)\n",
    "for library in ['cornac']:\n",
    "    try:\n",
    "        recommendations = loader.list_datasets_by_library(library)\n",
    "        print(f\"  âœ“ {library.upper()}:\")\n",
    "        print(f\"    Default dataset: {recommendations['config']['default_dataset']}\")\n",
    "        print(f\"    Available datasets: {len(recommendations['recommended_datasets'])}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  âœ— Error getting {library} recommendations: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DataLoader ready for use! ğŸš€\")\n",
    "print(\"=\" * 80)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c74b51ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â loader.help()  # Display the help guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5faeb97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
