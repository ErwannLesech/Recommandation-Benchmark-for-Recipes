{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4b4aedb",
   "metadata": {},
   "source": [
    "# User-based Collaborative Filtering\n",
    "\n",
    "User-based k-Nearest Neighbors (UserKNN) is another collaborative filtering algorithm used in\n",
    "recommendation systems. The core idea behind UserKNN is to make recommendations based on the\n",
    "preferences of similar users. UserKNN is intuitive and leverages the idea that users who have rated\n",
    "items similarly in the past will continue to have similar preferences. It’s especially effective when users\n",
    "have a rich history of interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a17a658",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/r-one/.local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# %pip install import_ipynb\n",
    "import import_ipynb \n",
    "import cornac\n",
    "from cornac.data import Dataset\n",
    "import cornac.metrics as met\n",
    "from cornac.eval_methods import BaseMethod\n",
    "from data_loader import DataLoader # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5760a8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/\"\n",
    "data_loader = DataLoader(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b6c5f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(513384, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ReviewId</th>\n",
       "      <th>RecipeId</th>\n",
       "      <th>AuthorId</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>826743</td>\n",
       "      <td>3745</td>\n",
       "      <td>345380</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1247176</td>\n",
       "      <td>26217</td>\n",
       "      <td>406131</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1250914</td>\n",
       "      <td>17123</td>\n",
       "      <td>355582</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>183560</td>\n",
       "      <td>123283</td>\n",
       "      <td>58104</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1255493</td>\n",
       "      <td>110139</td>\n",
       "      <td>383795</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ReviewId  RecipeId  AuthorId  Rating\n",
       "0    826743      3745    345380       4\n",
       "1   1247176     26217    406131       1\n",
       "2   1250914     17123    355582       5\n",
       "3    183560    123283     58104       4\n",
       "4   1255493    110139    383795       5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset, test_dataset = data_loader.load_for_cornac(dataset_type='split')\n",
    "print(train_dataset.shape)\n",
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9bbb0c",
   "metadata": {},
   "source": [
    "## User-based Collaborative Filtering (UserKNN)\n",
    "\n",
    "User-based collaborative filtering finds users who are similar to the target user and recommends items that these similar users have liked. The algorithm works as follows:\n",
    "\n",
    "1. **Find Similar Users**: Calculate similarity between users based on their rating patterns\n",
    "2. **Neighborhood Selection**: Select k most similar users (k-nearest neighbors)\n",
    "3. **Prediction**: Predict ratings for unrated items based on similar users' ratings\n",
    "4. **Recommendation**: Recommend items with highest predicted ratings\n",
    "\n",
    "### Key Parameters:\n",
    "- **k**: Number of similar users to consider (neighborhood size)\n",
    "- **similarity**: Similarity metric (cosine, pearson, etc.)\n",
    "- **min_support**: Minimum number of common items between users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "559904e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "USER-BASED COLLABORATIVE FILTERING (UserKNN) EVALUATION\n",
      "================================================================================\n",
      "\n",
      "Testing UserKNN with k=5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17748/17748 [00:00<00:00, 28646.82it/s]\n",
      "/home/r-one/.local/lib/python3.11/site-packages/cornac/models/recommender.py:322: UserWarning: Model is already fitted. Re-fitting will overwrite the previous model.\n",
      "  warnings.warn(\n",
      "100%|██████████| 17748/17748 [00:00<00:00, 25585.60it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[32m     29\u001b[39m metrics = [\n\u001b[32m     30\u001b[39m     met.MSE(),\n\u001b[32m     31\u001b[39m     met.RMSE(),\n\u001b[32m   (...)\u001b[39m\u001b[32m     35\u001b[39m     met.NDCG(k=k),\n\u001b[32m     36\u001b[39m ]\n\u001b[32m     37\u001b[39m eval_method = BaseMethod.from_splits(train_dataset[[\u001b[33m'\u001b[39m\u001b[33mAuthorId\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mRecipeId\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mRating\u001b[39m\u001b[33m'\u001b[39m]].values, test_dataset[[\u001b[33m'\u001b[39m\u001b[33mAuthorId\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mRecipeId\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mRating\u001b[39m\u001b[33m'\u001b[39m]].values)\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m results = \u001b[43meval_method\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_knn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_based\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m metrics \u001b[38;5;129;01min\u001b[39;00m results:\n\u001b[32m     41\u001b[39m     \u001b[38;5;28mprint\u001b[39m(metrics)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/cornac/eval_methods/base_method.py:747\u001b[39m, in \u001b[36mBaseMethod.evaluate\u001b[39m\u001b[34m(self, model, metrics, user_based, show_validation)\u001b[39m\n\u001b[32m    745\u001b[39m start = time.time()\n\u001b[32m    746\u001b[39m model.transform(\u001b[38;5;28mself\u001b[39m.test_set)\n\u001b[32m--> \u001b[39m\u001b[32m747\u001b[39m test_result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    748\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    749\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    750\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtest_set\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtest_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    751\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_set\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    752\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrating_threshold\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrating_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    753\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexclude_unknowns\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexclude_unknowns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    754\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrating_metrics\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrating_metrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    755\u001b[39m \u001b[43m    \u001b[49m\u001b[43mranking_metrics\u001b[49m\u001b[43m=\u001b[49m\u001b[43mranking_metrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    756\u001b[39m \u001b[43m    \u001b[49m\u001b[43muser_based\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_based\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    757\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    758\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    759\u001b[39m test_time = time.time() - start\n\u001b[32m    760\u001b[39m test_result.metric_avg_results[\u001b[33m\"\u001b[39m\u001b[33mTrain (s)\u001b[39m\u001b[33m\"\u001b[39m] = train_time\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/cornac/eval_methods/base_method.py:682\u001b[39m, in \u001b[36mBaseMethod.eval\u001b[39m\u001b[34m(model, train_set, test_set, val_set, rating_threshold, exclude_unknowns, user_based, rating_metrics, ranking_metrics, verbose)\u001b[39m\n\u001b[32m    679\u001b[39m     metric_avg_results[mt.name] = avg_results[i]\n\u001b[32m    680\u001b[39m     metric_user_results[mt.name] = user_results[i]\n\u001b[32m--> \u001b[39m\u001b[32m682\u001b[39m avg_results, user_results = \u001b[43mranking_eval\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    683\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    684\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m=\u001b[49m\u001b[43mranking_metrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    685\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    686\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtest_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    687\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    688\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrating_threshold\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrating_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    689\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexclude_unknowns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude_unknowns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    690\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    691\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    692\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, mt \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(ranking_metrics):\n\u001b[32m    693\u001b[39m     metric_avg_results[mt.name] = avg_results[i]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/cornac/eval_methods/base_method.py:208\u001b[39m, in \u001b[36mranking_eval\u001b[39m\u001b[34m(model, metrics, train_set, test_set, val_set, rating_threshold, exclude_unknowns, verbose)\u001b[39m\n\u001b[32m    205\u001b[39m u_gt_pos_items = np.nonzero(u_gt_pos_mask)[\u001b[32m0\u001b[39m]\n\u001b[32m    206\u001b[39m u_gt_neg_items = np.nonzero(u_gt_neg_mask)[\u001b[32m0\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m208\u001b[39m item_rank, item_scores = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrank\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[43m    \u001b[49m\u001b[43muser_idx\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem_indices\u001b[49m\u001b[43m=\u001b[49m\u001b[43mitem_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_k\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, mt \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(metrics):\n\u001b[32m    213\u001b[39m     mt_score = mt.compute(\n\u001b[32m    214\u001b[39m         gt_pos=u_gt_pos_items,\n\u001b[32m    215\u001b[39m         gt_neg=u_gt_neg_items,\n\u001b[32m   (...)\u001b[39m\u001b[32m    218\u001b[39m         item_indices=item_indices,\n\u001b[32m    219\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/cornac/models/recommender.py:501\u001b[39m, in \u001b[36mRecommender.rank\u001b[39m\u001b[34m(self, user_idx, item_indices, k, **kwargs)\u001b[39m\n\u001b[32m    499\u001b[39m \u001b[38;5;66;03m# obtain item scores from the model\u001b[39;00m\n\u001b[32m    500\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m501\u001b[39m     known_item_scores = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    502\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ScoreException:\n\u001b[32m    503\u001b[39m     known_item_scores = np.ones(\u001b[38;5;28mself\u001b[39m.total_items) * \u001b[38;5;28mself\u001b[39m.default_score()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/cornac/models/knn/recom_knn.py:252\u001b[39m, in \u001b[36mUserKNN.score\u001b[39m\u001b[34m(self, user_idx, item_idx)\u001b[39m\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.mean_arr[user_idx] + weighted_avg\n\u001b[32m    251\u001b[39m weighted_avg = np.zeros(\u001b[38;5;28mself\u001b[39m.num_items)\n\u001b[32m--> \u001b[39m\u001b[32m252\u001b[39m \u001b[43mcompute_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msim_mat\u001b[49m\u001b[43m[\u001b[49m\u001b[43muser_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtoarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miu_mat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mindptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miu_mat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miu_mat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m    \u001b[49m\u001b[43mk\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_threads\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweighted_avg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    262\u001b[39m known_item_scores = \u001b[38;5;28mself\u001b[39m.mean_arr[user_idx] + weighted_avg\n\u001b[32m    264\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m known_item_scores\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from cornac.models import UserKNN\n",
    "from cornac.eval_methods import RatioSplit\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Uncomment the following lines to limit the dataset size for quick testing\n",
    "\"\"\"train_dataset = train_dataset[:1000]  # Limit to 1000 for quick testing\n",
    "test_dataset = test_dataset[:20] # Limit to 20 for quick testing\n",
    "print(f\"Train dataset size: {train_dataset.shape}\"\n",
    "      f\"\\nTest dataset size: {test_dataset.shape}\")\"\"\"\n",
    "\n",
    "cornac_train_dataset = Dataset.from_uir(train_dataset[['AuthorId', 'RecipeId', 'Rating']].values.tolist(), seed=42)\n",
    "\n",
    "metrics = [\n",
    "    met.MSE(),\n",
    "    met.RMSE(),\n",
    "    met.MAE(),\n",
    "    met.Precision(k=10),\n",
    "    met.Recall(k=10),\n",
    "    met.NDCG(k=10),\n",
    "]\n",
    "eval_method = BaseMethod.from_splits(train_dataset[['AuthorId', 'RecipeId', 'Rating']].values, test_dataset[['AuthorId', 'RecipeId', 'Rating']].values)\n",
    "\n",
    "k_values = [5, 10, 20, 50]\n",
    "user_knn_results = []\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"USER-BASED COLLABORATIVE FILTERING (UserKNN) EVALUATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for k in k_values:\n",
    "    print(f\"\\nTesting UserKNN with k={k}...\")\n",
    "    user_knn = UserKNN(k=k, similarity='cosine', verbose=True)\n",
    "    start_time = time.time()\n",
    "    user_knn.fit(cornac_train_dataset)\n",
    "    total_time = time.time() - start_time\n",
    "    \n",
    "    # Evaluate metrics\n",
    "    results = eval_method.evaluate(user_knn, metrics=metrics, user_based=False)\n",
    "    \n",
    "    for metrics in results:\n",
    "        print(metrics)\n",
    "    \n",
    "    model_result = {\n",
    "        'model': f'UserKNN(k={k})',\n",
    "        'k': k,\n",
    "        'results': results,\n",
    "        'total_time': total_time\n",
    "    }\n",
    "    user_knn_results.append(model_result)\n",
    "    print(f\"  Total time: {total_time:.2f}s\")\n",
    "\n",
    "# Display results in a nice table\n",
    "user_knn_df = pd.DataFrame(user_knn_results)\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"USER-BASED COLLABORATIVE FILTERING RESULTS SUMMARY\")\n",
    "print(f\"{'='*80}\")\n",
    "print(user_knn_df.to_string(index=False, float_format='%.4f'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e66135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result values: [' 0.6412 ', ' 0.7271 ', ' 0.8527 ', ' 0.0509 ', '      0.0200 ', '   0.1000 ', '    0.0252 ', '   0.0146']\n",
      "Result values: [' 0.6412 ', ' 0.7271 ', ' 0.8527 ', '  0.1004 ', '       0.0250 ', '    0.2500 ', '    0.0233 ', '   0.0170']\n",
      "Result values: [' 0.6412 ', ' 0.7271 ', ' 0.8527 ', '  0.1663 ', '       0.0250 ', '    0.5000 ', '    0.0231 ', '   0.0182']\n",
      "Result values: [' 0.6412 ', ' 0.7271 ', ' 0.8527 ', '  0.1663 ', '       0.0100 ', '    0.5000 ', '    0.0219 ', '   0.0202']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>k</th>\n",
       "      <th>total_time</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Precision@50</th>\n",
       "      <th>Recall@50</th>\n",
       "      <th>NDCG@50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UserKNN(k=5)</td>\n",
       "      <td>5</td>\n",
       "      <td>0.039051</td>\n",
       "      <td>0.6412</td>\n",
       "      <td>0.7271</td>\n",
       "      <td>0.8527</td>\n",
       "      <td>0.0509</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UserKNN(k=10)</td>\n",
       "      <td>10</td>\n",
       "      <td>0.033474</td>\n",
       "      <td>0.6412</td>\n",
       "      <td>0.7271</td>\n",
       "      <td>0.8527</td>\n",
       "      <td>0.1004</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UserKNN(k=20)</td>\n",
       "      <td>20</td>\n",
       "      <td>0.024688</td>\n",
       "      <td>0.6412</td>\n",
       "      <td>0.7271</td>\n",
       "      <td>0.8527</td>\n",
       "      <td>0.1663</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UserKNN(k=50)</td>\n",
       "      <td>50</td>\n",
       "      <td>0.032905</td>\n",
       "      <td>0.6412</td>\n",
       "      <td>0.7271</td>\n",
       "      <td>0.8527</td>\n",
       "      <td>0.1663</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model   k  total_time     MSE    RMSE     MAE  Precision@50  \\\n",
       "0   UserKNN(k=5)   5    0.039051  0.6412  0.7271  0.8527        0.0509   \n",
       "1  UserKNN(k=10)  10    0.033474  0.6412  0.7271  0.8527        0.1004   \n",
       "2  UserKNN(k=20)  20    0.024688  0.6412  0.7271  0.8527        0.1663   \n",
       "3  UserKNN(k=50)  50    0.032905  0.6412  0.7271  0.8527        0.1663   \n",
       "\n",
       "   Recall@50  NDCG@50  \n",
       "0      0.020     0.10  \n",
       "1      0.025     0.25  \n",
       "2      0.025     0.50  \n",
       "3      0.010     0.50  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_metrics(results_tuple, metrics=[\n",
    "        met.MSE(),\n",
    "        met.RMSE(),\n",
    "        met.MAE(),\n",
    "        met.Precision(k=k),\n",
    "        met.Recall(k=k),\n",
    "        met.NDCG(k=k),\n",
    "    ]):\n",
    "    \"\"\"\n",
    "    Extracts metrics from the results tuple returned by Cornac evaluation.\n",
    "    \"\"\"\n",
    "    # print(results_tuple[0])\n",
    "    cornac_metrics = results_tuple[0]\n",
    "    string_metrics = str(cornac_metrics)\n",
    "    \n",
    "    result_line = string_metrics.split('\\n')[2].strip()\n",
    "    # print(f\"Result line: {result_line}\")\n",
    "    \n",
    "    result_values = result_line.split(\"|\")[1:]\n",
    "    # print(f\"Result values: {result_values}\")\n",
    "    \n",
    "    metrics_dict = {}\n",
    "    for metric, value in zip(metrics, result_values):\n",
    "        metric_name = metric.name if hasattr(metric, 'name') else str(metric)\n",
    "        metrics_dict[metric_name] = float(value.strip())\n",
    "            \n",
    "    # print(f\"Extracted metrics: {metrics_dict}\")\n",
    "    return metrics_dict\n",
    "\n",
    "for result in user_knn_results:\n",
    "    result['results'] = extract_metrics(result['results'], metrics=[\n",
    "        met.MSE(),\n",
    "        met.RMSE(),\n",
    "        met.MAE(),\n",
    "        met.Precision(k=k),\n",
    "        met.Recall(k=k),\n",
    "        met.NDCG(k=k),\n",
    "    ])\n",
    "\n",
    "for result in user_knn_results:\n",
    "    for metric_name, value in result['results'].items():\n",
    "        result[metric_name] = value\n",
    "    del result['results']\n",
    "\n",
    "user_knn_df = pd.DataFrame(user_knn_results)\n",
    "user_knn_df\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
